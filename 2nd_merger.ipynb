{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Merger\n",
    "\n",
    "Merge between df_unmerged_companies.csv and new aida's extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from thefuzz import process, fuzz\n",
    "from src.ingestion import download_from_drive\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: '../data/file_id.json'\n",
      "Please ensure the required file '../data/file_id.json' exists.\n"
     ]
    }
   ],
   "source": [
    "# PAY ATTENTION: if not updated, it will overwrite the files\n",
    "\n",
    "# set starting db links\n",
    "df_crunchbase = pd.read_csv('data/df_unmerged_companies_2.csv')\n",
    "df_aida = download_from_drive(\"bolai_acquired\")\n",
    "\n",
    "# set names of the files where the results will be saved\n",
    "df_merged_companies = \"df_merged_companies_3.csv\"\n",
    "df_unmerged_companies = \"df_unmerged_companies_3.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the databases\n",
    "df_anagrafica = df_aida\n",
    "#df_anagrafica = download_from_drive(\"csv_startup_anagrafica\")\n",
    "#df_crunchbase = download_from_drive(\"estrazione_crunchbase_5k\")\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "print(\"Startup Anagrafica Dataset:\")\n",
    "display(df_anagrafica.head())\n",
    "\n",
    "print(\"\\nCrunchbase Dataset:\")\n",
    "display(df_crunchbase.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulisci_stringa(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Enhanced string cleaning function with more sophisticated preprocessing\n",
    "    for better company name matching.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return str(s)\n",
    "    \n",
    "    s = s.strip().lower()\n",
    "    \n",
    "    # Handle common company type abbreviations (more comprehensive list)\n",
    "    s = re.sub(r'\\b(srl|s\\.r\\.l|s\\.r\\.l\\.|s.r.l|spa|s\\.p\\.a|s\\.p\\.a\\.|s.p.a|' + \n",
    "               r'inc|incorporated|llc|ltd|limited|gmbh|' + \n",
    "               r'corp|corporation|co\\.|company|group|holding|' + \n",
    "               r'sas|sapa|snc|scarl)(?=\\s|$|\\b)', '', s)\n",
    "    \n",
    "    # Handle common abbreviations\n",
    "    s = s.replace(\"int'l\", \"international\")\n",
    "    s = s.replace(\"tech.\", \"technology\")\n",
    "    s = s.replace(\"tech\", \"technology\")\n",
    "    s = s.replace(\"&\", \"and\")\n",
    "    \n",
    "    # Remove geographical designations that might differ\n",
    "    s = re.sub(r'\\b(italy|italia|italian|italiano|italiana)\\b', '', s)\n",
    "    \n",
    "    # Remove special characters and extra spaces\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
    "    \n",
    "    # Remove common filler words\n",
    "    s = re.sub(r'\\b(the|di|del|della|e|a|in|for|of)\\b', ' ', s)\n",
    "    \n",
    "    # Replace multiple spaces with single space and trim\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "def calculate_composite_score(name1, name2):\n",
    "    \"\"\"\n",
    "    Calculate a composite score using multiple string matching algorithms\n",
    "    to better identify company name matches.\n",
    "    \n",
    "    Returns: float between 0-100 representing match confidence\n",
    "    \"\"\"\n",
    "    # Standard ratios check different aspects of string similarity\n",
    "    ratio = fuzz.ratio(name1, name2)\n",
    "    partial_ratio = fuzz.partial_ratio(name1, name2)\n",
    "    token_sort_ratio = fuzz.token_sort_ratio(name1, name2)\n",
    "    token_set_ratio = fuzz.token_set_ratio(name1, name2)\n",
    "    \n",
    "    # Calculate a weighted average - giving more weight to token methods\n",
    "    # as they handle word order differences better for company names\n",
    "    weighted_score = (\n",
    "        ratio * 0.15 +\n",
    "        partial_ratio * 0.25 +\n",
    "        token_sort_ratio * 0.3 +\n",
    "        token_set_ratio * 0.3\n",
    "    )\n",
    "    \n",
    "    # Additional bonus for exact token matching\n",
    "    tokens1 = set(name1.split())\n",
    "    tokens2 = set(name2.split())\n",
    "    \n",
    "    # If there are significant shared tokens, boost the score\n",
    "    if len(tokens1) > 0 and len(tokens2) > 0:\n",
    "        shared = tokens1.intersection(tokens2)\n",
    "        if len(shared) >= 2:  # At least 2 significant words match\n",
    "            weighted_score += min(10, len(shared) * 2.5)  # Bonus up to 10 points\n",
    "    \n",
    "    # Cap at 100\n",
    "    return min(100, weighted_score)\n",
    "\n",
    "def enhanced_fuzzy_merge(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    key1: str,\n",
    "    key2: str,\n",
    "    threshold: int = 75\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enhanced version of fuzzy_merge that uses multiple matching techniques\n",
    "    for more accurate company name matching.\n",
    "    \"\"\"\n",
    "    # Copia dei DataFrame per non modificare gli originali\n",
    "    df1_clean = df1.copy()\n",
    "    df2_clean = df2.copy()\n",
    "    \n",
    "    # Creiamo colonne \"pulite\" per il matching con la funzione migliorata\n",
    "    df1_clean['key_clean'] = df1_clean[key1].apply(pulisci_stringa)\n",
    "    df2_clean['key_clean'] = df2_clean[key2].apply(pulisci_stringa)\n",
    "    \n",
    "    # Create clean keys and make a dictionary for lookup\n",
    "    unique_keys2 = df2_clean['key_clean'].unique().tolist()\n",
    "    \n",
    "    # Lista per salvare i risultati\n",
    "    risultati = []\n",
    "    \n",
    "    # Track already matched names in df2 to avoid duplicates\n",
    "    matched_df2_indices = set()\n",
    "\n",
    "    for idx1, row in tqdm(df1_clean.iterrows(), total=len(df1_clean), desc=\"Matching records\"):\n",
    "        name_to_match = row['key_clean']\n",
    "        \n",
    "        # Skip empty names\n",
    "        if not name_to_match.strip():\n",
    "            continue\n",
    "            \n",
    "        # Get top 5 potential matches instead of just one\n",
    "        top_matches = process.extract(name_to_match, unique_keys2, \n",
    "                                     scorer=fuzz.token_set_ratio, limit=5)\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        best_match_row = None\n",
    "        \n",
    "        # Evaluate each potential match with our composite score\n",
    "        for match_name, base_score in top_matches:\n",
    "            # Calculate more sophisticated score\n",
    "            composite_score = calculate_composite_score(name_to_match, match_name)\n",
    "            \n",
    "            # Find matching rows\n",
    "            match_rows = df2_clean[df2_clean['key_clean'] == match_name]\n",
    "            \n",
    "            # Skip if we've already used all these matches\n",
    "            if all(idx in matched_df2_indices for idx in match_rows.index):\n",
    "                continue\n",
    "                \n",
    "            # Get first available match\n",
    "            for idx2, match_row in match_rows.iterrows():\n",
    "                if idx2 not in matched_df2_indices and composite_score > best_score:\n",
    "                    best_score = composite_score\n",
    "                    best_match = match_name\n",
    "                    best_match_row = match_row\n",
    "                    best_match_idx = idx2\n",
    "                    break\n",
    "        \n",
    "        # Process the best match if it meets the threshold\n",
    "        if best_match and best_score >= threshold:\n",
    "            # Mark this df2 row as matched\n",
    "            matched_df2_indices.add(best_match_idx)\n",
    "            \n",
    "            # Build combined data dictionary\n",
    "            combined_data = {}\n",
    "            \n",
    "            # Data from df1\n",
    "            for col in df1_clean.columns:\n",
    "                if col != 'key_clean':  # Exclude auxiliary column\n",
    "                    combined_data[f\"anagrafica_{col}\"] = row[col]\n",
    "            \n",
    "            # Data from df2\n",
    "            for col in df2_clean.columns:\n",
    "                if col != 'key_clean':  # Exclude auxiliary column\n",
    "                    combined_data[f\"crunchbase_{col}\"] = best_match_row[col]\n",
    "            \n",
    "            combined_data['similarity_score'] = best_score\n",
    "            combined_data['composite_match'] = True\n",
    "            \n",
    "            risultati.append(combined_data)\n",
    "        else:\n",
    "            # If no good match, keep just df1 data\n",
    "            combined_data = {}\n",
    "            for col in df1_clean.columns:\n",
    "                if col != 'key_clean':\n",
    "                    combined_data[f\"anagrafica_{col}\"] = row[col]\n",
    "            \n",
    "            for col in df2_clean.columns:\n",
    "                if col != 'key_clean':\n",
    "                    combined_data[f\"crunchbase_{col}\"] = None\n",
    "                    \n",
    "            combined_data['similarity_score'] = best_score if best_score else 0\n",
    "            combined_data['composite_match'] = False\n",
    "            risultati.append(combined_data)\n",
    "    \n",
    "    # Add remaining df2 rows that weren't matched\n",
    "    if len(matched_df2_indices) < len(df2_clean):\n",
    "        for idx2, row in df2_clean.iterrows():\n",
    "            if idx2 not in matched_df2_indices:\n",
    "                combined_data = {}\n",
    "                \n",
    "                # Empty df1 data\n",
    "                for col in df1_clean.columns:\n",
    "                    if col != 'key_clean':\n",
    "                        combined_data[f\"anagrafica_{col}\"] = None\n",
    "                \n",
    "                # df2 data\n",
    "                for col in df2_clean.columns:\n",
    "                    if col != 'key_clean':\n",
    "                        combined_data[f\"crunchbase_{col}\"] = row[col]\n",
    "                \n",
    "                combined_data['similarity_score'] = 0\n",
    "                combined_data['composite_match'] = False\n",
    "                risultati.append(combined_data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_risultati = pd.DataFrame(risultati)\n",
    "    return df_risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure ipywidgets is installed to fix the IProgress error\n",
    "#%pip install ipywidgets\n",
    "\n",
    "# Eseguiamo il merge con una soglia appropriata\n",
    "df_merged = enhanced_fuzzy_merge(df_anagrafica, df_crunchbase, \"Ragione sociale\", \"Organization Name\", threshold=85)\n",
    "\n",
    "# Visualizziamo un campione dei risultati\n",
    "print(f\"Numero di record totali dopo il merge: {len(df_merged)}\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un ID unico per ogni coppia abbinata\n",
    "# Utilizziamo una combinazione dei valori originali per creare un ID significativo\n",
    "\n",
    "def create_unique_id(row):\n",
    "    # Prendiamo il nome dalla colonna anagrafica se disponibile, altrimenti da crunchbase\n",
    "    company_name = str(row['anagrafica_Ragione sociale']) if pd.notna(row['anagrafica_Ragione sociale']) else \\\n",
    "                  str(row['crunchbase_Organization Name']) if pd.notna(row['crunchbase_Organization Name']) else 'unknown'\n",
    "    \n",
    "    # Pulizia base per l'ID\n",
    "    clean_name = re.sub(r'[^\\w]', '', company_name.lower())\n",
    "    \n",
    "    # Aggiungiamo un valore numerico progressivo per garantire l'unicità\n",
    "    return f\"comp_{clean_name[:20]}\"\n",
    "\n",
    "# Creiamo inizialmente l'ID senza controllo duplicati\n",
    "df_merged['company_id'] = df_merged.apply(create_unique_id, axis=1)\n",
    "\n",
    "# Controlliamo e gestiamo i duplicati aggiungendo un numero progressivo\n",
    "id_counts = df_merged['company_id'].value_counts()\n",
    "duplicated_ids = id_counts[id_counts > 1].index.tolist()\n",
    "\n",
    "# Per ogni ID duplicato, aggiungiamo un contatore\n",
    "for dup_id in duplicated_ids:\n",
    "    # Identifichiamo tutte le righe con questo ID\n",
    "    mask = df_merged['company_id'] == dup_id\n",
    "    # Aggiungiamo un contatore progressivo\n",
    "    df_merged.loc[mask, 'company_id'] = [\n",
    "        f\"{dup_id}_{i}\" for i in range(1, mask.sum() + 1)\n",
    "    ]\n",
    "\n",
    "# Verifichiamo che non ci siano più duplicati\n",
    "print(f\"ID unici: {df_merged['company_id'].nunique()}\")\n",
    "print(f\"Totale record: {len(df_merged)}\")\n",
    "\n",
    "# Visualizziamo i risultati con i nuovi ID\n",
    "df_merged[['company_id', 'anagrafica_Ragione sociale', 'crunchbase_Organization Name', 'similarity_score']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestione delle colonne - manteniamo i nomi originali ma riorganizziamo il dataset\n",
    "# Creiamo un nuovo DataFrame più pulito con le colonne principali\n",
    "\n",
    "cols_to_keep = [\n",
    "    'company_id',  # Il nostro ID unico\n",
    "    'anagrafica_Ragione sociale',\n",
    "    'crunchbase_Organization Name',\n",
    "    'similarity_score'\n",
    "    # Aggiungi qui altre colonne di interesse\n",
    "]\n",
    "\n",
    "df_final = df_merged[cols_to_keep].copy()\n",
    "\n",
    "# Rinominiamo le colonne per chiarezza mantenendo i nomi originali\n",
    "df_final = df_final.rename(columns={\n",
    "    'anagrafica_Ragione sociale': 'Ragione sociale',\n",
    "    'crunchbase_Organization Name': 'Organization Name'\n",
    "})\n",
    "\n",
    "# Visualizza il dataset finale\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opzionale: salva il dataset finale\n",
    "# df_final.to_csv('merged_company_data.csv', index=False)\n",
    "\n",
    "# Statistiche finali\n",
    "print(f\"Totale record nel dataset finale: {len(df_final)}\")\n",
    "print(f\"Record con match di alta qualità (score >= 90): {(df_final['similarity_score'] >= 90).sum()}\")\n",
    "print(f\"Record con match medio (score 80-90): {((df_final['similarity_score'] >= 80) & (df_final['similarity_score'] < 90)).sum()}\")\n",
    "print(f\"Record con match basso (score < 80): {(df_final['similarity_score'] < 80).sum() if 'similarity_score' in df_final.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteggio delle corrispondenze tra anagrafica_Ragione sociale e crunchbase_Organization Name\n",
    "\n",
    "# Filtriamo le righe dove entrambi i campi non sono null\n",
    "matched_companies = df_merged[\n",
    "    pd.notna(df_merged['anagrafica_Ragione sociale']) & \n",
    "    pd.notna(df_merged['crunchbase_Organization Name'])\n",
    "]\n",
    "\n",
    "# Contiamo quante corrispondenze abbiamo trovato\n",
    "total_matches = len(matched_companies)\n",
    "total_anagrafica = df_merged['anagrafica_Ragione sociale'].notna().sum()\n",
    "total_crunchbase = df_merged['crunchbase_Organization Name'].notna().sum()\n",
    "\n",
    "print(f\"Totale aziende con corrispondenza tra i due database: {total_matches}\")\n",
    "print(f\"Totale aziende nel database anagrafica: {total_anagrafica}\")\n",
    "print(f\"Totale aziende nel database crunchbase: {total_crunchbase}\")\n",
    "print(f\"Percentuale di aziende anagrafica con match: {(total_matches / total_anagrafica * 100):.2f}%\")\n",
    "print(f\"Percentuale di aziende crunchbase con match: {(total_matches / total_crunchbase * 100):.2f}%\")\n",
    "\n",
    "# Visualizziamo alcuni esempi di corrispondenze con i relativi score\n",
    "print(\"\\nEsempi di corrispondenze trovate (ordinate per score):\")\n",
    "display(matched_companies[['company_id', 'anagrafica_Ragione sociale', \n",
    "                          'crunchbase_Organization Name', 'similarity_score']]\n",
    "       .sort_values(by='similarity_score', ascending=False).head(10))\n",
    "\n",
    "# Distribuzione degli score per le corrispondenze trovate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(matched_companies['similarity_score'], bins=20)\n",
    "plt.title('Distribuzione degli score per le corrispondenze trovate')\n",
    "plt.xlabel('Score di similarità')\n",
    "plt.ylabel('Numero di corrispondenze')\n",
    "plt.axvline(x=85, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_merged DataFrame to a CSV file in the 'data' folder\n",
    "df_merged.to_csv(f\"data/{df_merged_companies}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unmerged companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where \"crunchbase_Organization Name\" is not null and \"anagrafica_Ragione sociale\" is null\n",
    "df_crunchbase_unmerged = df_merged[\n",
    "    df_merged['crunchbase_Organization Name'].notna() & df_merged['anagrafica_Ragione sociale'].isna()\n",
    "]\n",
    "\n",
    "# Select only the columns that begin with \"crunchbase_\"\n",
    "df_crunchbase_unmerged = df_crunchbase_unmerged[\n",
    "    [col for col in df_merged.columns if col.startswith(\"crunchbase_\")]\n",
    "]\n",
    "\n",
    "# Rename the columns to remove the \"crunchbase_\" prefix\n",
    "df_crunchbase_unmerged.columns = df_crunchbase_unmerged.columns.str.replace('crunchbase_', '', regex=False)\n",
    "df_crunchbase_unmerged.head()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_crunchbase_unmerged.shape\n",
    "\n",
    "# Save the crunchbase_only_companies DataFrame to a CSV file in the 'data' folder\n",
    "df_crunchbase_unmerged.to_csv(f\"data/{df_unmerged_companies}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unmatched_crunchbase_locations():\n",
    "    \"\"\"\n",
    "    Estrae gli Headquarters Location dal database Crunchbase per le aziende\n",
    "    che sono presenti solo in Crunchbase (senza corrispondenza in anagrafica).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame contenente Organization Name e Headquarters Location\n",
    "        delle aziende che sono solo in Crunchbase\n",
    "    \"\"\"\n",
    "    # Filtriamo le righe dove c'è un valore in crunchbase_Organization Name\n",
    "    # ma non in anagrafica_Ragione sociale\n",
    "    unmatched_cb = df_merged[\n",
    "        pd.notna(df_merged['crunchbase_Organization Name']) & \n",
    "        pd.isna(df_merged['anagrafica_Ragione sociale'])\n",
    "    ].copy()\n",
    "    \n",
    "    # Selezioniamo solo le colonne di interesse\n",
    "    result = unmatched_cb[['crunchbase_Organization Name', 'crunchbase_Headquarters Location']]\n",
    "    \n",
    "    # Rinominiamo le colonne per maggiore chiarezza\n",
    "    result = result.rename(columns={\n",
    "        'crunchbase_Organization Name': 'Organization Name',\n",
    "        'crunchbase_Headquarters Location': 'Headquarters Location'\n",
    "    })\n",
    "    \n",
    "    # Riordiniamo e resettiamo l'indice\n",
    "    result = result.sort_values(by='Organization Name').reset_index(drop=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Eseguiamo la funzione e mostriamo i risultati\n",
    "unmatched_locations = extract_unmatched_crunchbase_locations()\n",
    "\n",
    "# Statistiche sulle sedi non corrispondenti\n",
    "print(f\"Totale organizzazioni solo in Crunchbase (senza match in anagrafica): {len(unmatched_locations)}\")\n",
    "\n",
    "# Contiamo la distribuzione delle sedi (top 10)\n",
    "if 'Headquarters Location' in unmatched_locations.columns and not unmatched_locations.empty:\n",
    "    location_counts = unmatched_locations['Headquarters Location'].value_counts().head(10)\n",
    "    print(\"\\nTop 10 sedi delle organizzazioni non corrispondenti:\")\n",
    "    display(location_counts)\n",
    "    \n",
    "    # Percentuale di valori mancanti nella colonna Headquarters Location\n",
    "    missing_pct = unmatched_locations['Headquarters Location'].isna().mean() * 100\n",
    "    print(f\"\\nPercentuale di valori mancanti nella colonna 'Headquarters Location': {missing_pct:.2f}%\")\n",
    "\n",
    "# Mostriamo i primi risultati\n",
    "print(\"\\nEsempi di organizzazioni solo in Crunchbase:\")\n",
    "display(unmatched_locations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crunchbase_only_companies():\n",
    "    \"\"\"\n",
    "    Estrae i nomi delle aziende che sono presenti solo nel database Crunchbase\n",
    "    e non hanno corrispondenza nel database Anagrafica.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame contenente solo i nomi delle aziende presenti esclusivamente in Crunchbase\n",
    "    \"\"\"\n",
    "    # Filtriamo le righe dove c'Ã¨ un valore in crunchbase_Organization Name\n",
    "    # ma non in anagrafica_Ragione sociale\n",
    "    crunchbase_only = df_merged[\n",
    "        pd.notna(df_merged['crunchbase_Organization Name']) & \n",
    "        pd.isna(df_merged['anagrafica_Ragione sociale'])\n",
    "    ].copy()\n",
    "    \n",
    "    # Selezioniamo solo la colonna con i nomi delle organizzazioni\n",
    "    result = crunchbase_only[['crunchbase_Organization Name']].copy()\n",
    "    \n",
    "    # Rinominiamo la colonna per maggiore chiarezza\n",
    "    result = result.rename(columns={\n",
    "        'crunchbase_Organization Name': 'Organization Name'\n",
    "    })\n",
    "    \n",
    "    # Rimuoviamo eventuali duplicati\n",
    "    result = result.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Riordiniamo alfabeticamente\n",
    "    result = result.sort_values(by='Organization Name').reset_index(drop=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Eseguiamo la funzione e mostriamo i risultati\n",
    "crunchbase_only_companies = get_crunchbase_only_companies()\n",
    "\n",
    "# Statistiche sulle aziende\n",
    "print(f\"Totale aziende presenti solo in Crunchbase (senza match in anagrafica): {len(crunchbase_only_companies)}\")\n",
    "\n",
    "# Mostriamo i primi risultati\n",
    "print(\"\\nEsempi di aziende solo in Crunchbase:\")\n",
    "display(crunchbase_only_companies.head(15))\n",
    "\n",
    "# Opzionale: verifichiamo la coda della lista\n",
    "print(\"\\nUltime aziende della lista:\")\n",
    "display(crunchbase_only_companies.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the crunchbase_only_companies DataFrame to a CSV file in the 'data' folder\n",
    "crunchbase_only_companies.to_csv(f\"data/{df_unmerged_companies}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
